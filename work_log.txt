- O primeiro passo consiste na escolha do framework
adequado para o scrapping.

- Foram descobertas as opções pandas, scrapy,
beautiful soup e selenium.

- Pandas foi descartado por ser muito limitado e
o beautiful soup por ser lento e não-portátil,
apesar de sua facilidade de uso. 
Fonte: https://www.youtube.com/watch?v=zucvHSQsKHA

- Agora a decidir entre scrapy e selenium.

- O scrapy tem como ponto forte sua velocidade.

- O selenium, apesar de lento, se destaca por 
sua capacidade de interação com o javascript.

- Dado o impasse, faz-se necessário
escolher primeiro quais páginas serão analisadas, 
para então decidir qual dos frameworks utilizar.

- Foram escolhidos portais de notícias econômicas,
sendo eles InfoMoney, Boletim Econômico e UOL Economia.

- Tags que indicam título do link da matéria
    - InfoMoney: "hl-title"
    - Boletim Econômico: "cs-entry__title "
    - UOL Economia: "thumb-title "

- Metadados de artigo do UOL:
    - Título: "i.custom-title"
    - Corpo do texto: "div.text"
    - Autor: "p.p-author-local" (Autor, Local)
    - Data: "p.p-author time"
    - URL: <meta property="og:url" content="https://economia.uol.com.br/imposto-de-renda/noticias/redacao/2021/03/23/fraudar-declaracao-do-imposto-de-renda-pode-dar-ate-5-anos-de-cadeia.htm">
    - Tags:

- Metadados de artigo do Boletim Econômico:
    - Título: "h1.cs-entry__title"
    - Corpo do texto: "div.entry-content"
    - Autor: "div.cs-entry__author-meta"
    - Data: "cs-meta-date"
    - Tags: "div.cs-entry__tags"
    - URL: <meta property="og:url" content="https://boletimeconomico.com.br/o-que-e-a-autonomia-do-banco-central/">

- Metadados de artigo da InfoMoney:
    - Título: "div.page-title-1"
    - Corpo do texto: "div.article-content"
    - Autor: "span.author-name"
    - Data: "time.entry-date"
    - URL: <meta property="og:url" content="https://www.infomoney.com.br/mercados/analistas-dizem-que-petrobras-e-vale-estao-baratas-mas-exposicao-politica-da-petroleira-torna-investimento-mais-arriscado/">
    - Tags: "ul.article-terms"

- A pesquisar mais a fundo as particularidades
de ambos os frameworks (scrapy e selenium) para
melhor tomada de decisão sobre qual utilizar.

- Fonte de pesquisa sobre Scrapy:
https://www.youtube.com/watch?v=ve_0h4Y8nuI&list=PLhTjy8cBISEqkN-5Ku_kXG4QW33sxQo0t

- Fonte de pesquisa sobre Selenium:
https://www.youtube.com/watch?v=Xjv1sY630Uc&list=PLzMcBGfZo4-n40rB1XaJ0ak1bemvlqumQ

- Cheguei a conclusão de que a melhor abordagem
seria a híbrida, utilizar scrapy para realizar
o scrape em si e o selenium apenas em último caso
para algum controle mais específico da página,
e.g., clicar em algum botão de aceitar cookies.

- A construir spider para o InfoMoney.

- Algumas das classes selecionadas via inspeção
encontravam-se incompletas, portanto, utilizarei
a extensão SelectorGadget.

- Spider do InfoMoney completo, 
tempo de execução: 3.343783s
Fonte: informado no Scrapy Stats
no log de execução

- Spider do Boletim Econômico completo, 
tempo de execução: 2.210992s
Fonte: informado no Scrapy Stats
no log de execução

- Spider do Uol Economia completo, 
tempo de execução: 4.629252s
Fonte: informado no Scrapy Stats
no log de execução

- O uso do selenium acabou não se
fazendo necessário, pois foi possível
fazer todos os scrapers apenas utilizando
o scrapy.

- A atualizar spiders para contagem de
parágrafos, o método utilizado será,
por simplicidade, a contagem de elementos 
do array do body.

- Ainda a atualizar para contagem de
palavras.

- A analisar a possibilidade de utilizar
o Zyte(Scrapy Cloud) para deploy, mas seu 
website está apresentando problemas.

- O site do Zyte está apresentando falhas,
será realizada nova tentativa de deploy
posteriormente com o Scrapyd.

- A encapsular dados raspados em containers.

- A persistir dados no MongoDB.

- A criar pipeline.

- Dados persistidos no MongoDB.

- A realizar deploy no Zyte.

- A corrigir erros de dependências do pip.

- Spiders no ar e a salvar dados no MongoDB Atlas.